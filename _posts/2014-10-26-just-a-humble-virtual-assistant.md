---
layout: post
published: true
title: "Siri-ndipity: Talking to Your Phone and Liking It"
category: science
author: "Danny Ben-David"
displaydate: October 26 2014
date: October 26 2014
tags: 
  - student
---

![](http://i.imgur.com/z2OFKCq.png)    
I'm amused by trying to imagine the meetings that went into designing the personality of Siri, Apple's personal voice-based assistant for your mobile iDevices. Siri's full of conversational bits and easter eggs, almost like a filtered [CleverBot](http://www.cleverbot.com/), so I get a kick out of picturing the policy and design groups debating how exactly Siri should respond to a myriad of prompts.

> "If someone keeps asking how Siri is doing? How many different responses should we provide?"    
> "Well, we don't want to limit Siri to just '_I feel good!_' and '_Very well, thank you!_'—we should also add one which uses the user's name. How about '_I am well, Bill._'?"    
> "That's _genius_, Jim! We'll get our linguistic grammar team on it right away." 

It sounds ridiculous, no? But it clearly matters to someone on the Siri team, and apparently to the Newman family as well. Judith Newman's [story of her son's friendship with Siri](http://nyti.ms/1yLmB6i "New York Times: To Siri, With Love") felt all too real to me: she describes how her thirteen-year-old son Gus, who falls on the autism spectrum, has found unlikely companionship in Siri, who can patiently provide information and tips to Gus' heart's delight. 

Gus isn't the only one who likes doing this, though: I regularly get a kick out of trying to converse with Siri. The conversations aren't particularly advanced, but the voice translation has at least gotten to the point where my vocal queries to WolframAlpha, a computational engine, through Siri are transcribed and passed along faithfully.

What's funny to me is how the modern version of Siri holds just enough humanity to pass by in simple conversation, but it used to be much more semantically driven. In one of my personal hipster-claims-to-fame, I had Siri the App before it was Siri the iOS Feature. Back in February of 2010, I saw [a Lifehacker article about a new free app which acted as a personal assistant](http://lifehacker.com/5465117/siri-is-a-personal-assistant-that-fits-in-your-pocket "Lifehacker: Siri Is a Personal Assistant that Fits in Your Pocket"), and I was immediately interested. You could ask Siri things in complex English sentences, or in broken drunk ramblings, and it would parse out meaning. Furthermore, it was _stateful_: you could ask for a list of nearby events the upcoming weekend, and then say "How about in [place] instead?" and Siri would know to keep the same query but tweak the location. This all fascinated me, and I wanted to play with it as soon as possible.

The main problem? Technology on my end. Siri had been designed for the iPhone, and I had [a third-generation iPod Touch](http://i.imgur.com/h6bjDfo.png) which lacked, among other things, a built-in microphone. Undaunted, I downloaded the app, and sat in my room trying to make the damn thing work. As a junior in high school, I didn't need dinner reservations at a classy Italian place or updates on the stock market, but it was fun to play with all the same. Soon after, Siri was acquired by some unknown company, and reappeared as a beta product within Apple's iOS. Siri had lost its stateful nature, and found itself as the voice of the iPhone itself. 

Last year I attended a fascinating talk by Johan Schalkwyk, head of Google's speech recognition team. He explained how ridiculously difficult it is to build a system which reliably interprets voice across the vast range of dialects, speech affects, and figures of speech. What particularly struck me at the time was his primary criticism of Siri: Schalkwyk felt that Siri's personification led to heightened—and unobtainable—expectations of humanity from the iPhone. When your phone can respond in informal ways to conversational language, it's easier to take out verbal abuse on that device as well, as it can respond accordingly. On the other hand, Google's voice-based search simply pulled information and didn't deliver small talk, so people were more likely to be happier with it as a product overall.

The story of Gus Newman, though, seems to counter Schalkwyk. Siri's methodical responses to Gus' profanities provided cool-headed education for him on what was and was not appropriate. A human conversation may not have extended that far, with the other person losing their cool on the umpteenth repeat of what was okay to say.

And personally, it's _fun_ to test Siri's conversational side. Sometimes she (does Siri get gendered pronouns?) irritates me, volunteering extra unwanted information:

> "Good night, Siri."    
> "Good night? But it's 6:03AM!"    
> "…Thank you for that. I really, _really_ needed to be reminded of that."

But it's still amusing to probe whatever conversational side Siri may have.